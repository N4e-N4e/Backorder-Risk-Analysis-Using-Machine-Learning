{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Model Development\n",
    "\n",
    "In this part, I develop unique pipelines for predicting backorder. I also **use the smart sample from Part 1** to fit and evaluate these pipelines. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the smart sample here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>min_bank</th>\n",
       "      <th>potential_issue</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   national_inv  lead_time  in_transit_qty  forecast_6_month  sales_6_month  \\\n",
       "0         153.0        4.0             0.0               0.0           54.0   \n",
       "1          34.0        8.0             0.0               0.0            0.0   \n",
       "2           0.0        8.0             0.0               6.0            0.0   \n",
       "3          17.0        2.0             0.0               0.0            6.0   \n",
       "4           0.0        2.0             0.0              46.0            0.0   \n",
       "\n",
       "   min_bank  potential_issue  pieces_past_due  perf_6_month_avg  local_bo_qty  \\\n",
       "0       0.0                0              0.0              0.73           0.0   \n",
       "1       0.0                0              0.0              0.90           0.0   \n",
       "2       1.0                0              0.0              0.46           0.0   \n",
       "3       0.0                0              0.0              0.76           0.0   \n",
       "4       0.0                0              0.0              1.00           0.0   \n",
       "\n",
       "   deck_risk  oe_constraint  ppap_risk  stop_auto_buy  rev_stop  \\\n",
       "0          0              0          0              1         0   \n",
       "1          0              0          1              1         0   \n",
       "2          0              0          0              1         0   \n",
       "3          0              0          0              1         0   \n",
       "4          0              0          0              1         0   \n",
       "\n",
       "   went_on_backorder  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  1  \n",
       "3                  0  \n",
       "4                  1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload your smart sample from local file \n",
    "# ----------------------------------\n",
    "dataset = pd.read_csv('newdf.csv').sample(frac = 1).reset_index(drop=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>national_inv</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>174.802500</td>\n",
       "      <td>1847.738607</td>\n",
       "      <td>-1194.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>116712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_time</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>7.035100</td>\n",
       "      <td>5.524954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_transit_qty</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>30.668900</td>\n",
       "      <td>552.593921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29937.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_6_month</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>301.937400</td>\n",
       "      <td>4059.444328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>267300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_6_month</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>271.635600</td>\n",
       "      <td>4801.258211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>373777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_bank</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>38.628300</td>\n",
       "      <td>463.948425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>29376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potential_issue</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.052844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pieces_past_due</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.126700</td>\n",
       "      <td>24.341350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.745943</td>\n",
       "      <td>0.268487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_bo_qty</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.842300</td>\n",
       "      <td>28.579645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck_risk</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.382616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oe_constraint</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.024489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppap_risk</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>0.340777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.973500</td>\n",
       "      <td>0.160625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_stop</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went_on_backorder</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count        mean          std     min   25%   50%  \\\n",
       "national_inv       10000.0  174.802500  1847.738607 -1194.0  1.00  5.00   \n",
       "lead_time          10000.0    7.035100     5.524954     0.0  2.00  8.00   \n",
       "in_transit_qty     10000.0   30.668900   552.593921     0.0  0.00  0.00   \n",
       "forecast_6_month   10000.0  301.937400  4059.444328     0.0  0.00  7.00   \n",
       "sales_6_month      10000.0  271.635600  4801.258211     0.0  0.00  8.00   \n",
       "min_bank           10000.0   38.628300   463.948425     0.0  0.00  0.00   \n",
       "potential_issue    10000.0    0.002800     0.052844     0.0  0.00  0.00   \n",
       "pieces_past_due    10000.0    2.126700    24.341350     0.0  0.00  0.00   \n",
       "perf_6_month_avg   10000.0    0.745943     0.268487     0.0  0.66  0.82   \n",
       "local_bo_qty       10000.0    1.842300    28.579645     0.0  0.00  0.00   \n",
       "deck_risk          10000.0    0.178100     0.382616     0.0  0.00  0.00   \n",
       "oe_constraint      10000.0    0.000600     0.024489     0.0  0.00  0.00   \n",
       "ppap_risk          10000.0    0.134100     0.340777     0.0  0.00  0.00   \n",
       "stop_auto_buy      10000.0    0.973500     0.160625     0.0  1.00  1.00   \n",
       "rev_stop           10000.0    0.000000     0.000000     0.0  0.00  0.00   \n",
       "went_on_backorder  10000.0    0.500000     0.500025     0.0  0.00  0.50   \n",
       "\n",
       "                     75%       max  \n",
       "national_inv       24.00  116712.0  \n",
       "lead_time           8.00      52.0  \n",
       "in_transit_qty      0.00   29937.0  \n",
       "forecast_6_month   44.00  267300.0  \n",
       "sales_6_month      39.00  373777.0  \n",
       "min_bank            4.00   29376.0  \n",
       "potential_issue     0.00       1.0  \n",
       "pieces_past_due     0.00     816.0  \n",
       "perf_6_month_avg    0.96       1.0  \n",
       "local_bo_qty        0.00    1980.0  \n",
       "deck_risk           0.00       1.0  \n",
       "oe_constraint       0.00       1.0  \n",
       "ppap_risk           0.00       1.0  \n",
       "stop_auto_buy       1.00       1.0  \n",
       "rev_stop            0.00       0.0  \n",
       "went_on_backorder   1.00       1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into Train/Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>min_bank</th>\n",
       "      <th>potential_issue</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   national_inv  lead_time  in_transit_qty  forecast_6_month  sales_6_month  \\\n",
       "0         153.0        4.0             0.0               0.0           54.0   \n",
       "1          34.0        8.0             0.0               0.0            0.0   \n",
       "2           0.0        8.0             0.0               6.0            0.0   \n",
       "3          17.0        2.0             0.0               0.0            6.0   \n",
       "4           0.0        2.0             0.0              46.0            0.0   \n",
       "\n",
       "   min_bank  potential_issue  pieces_past_due  perf_6_month_avg  local_bo_qty  \\\n",
       "0       0.0                0              0.0              0.73           0.0   \n",
       "1       0.0                0              0.0              0.90           0.0   \n",
       "2       1.0                0              0.0              0.46           0.0   \n",
       "3       0.0                0              0.0              0.76           0.0   \n",
       "4       0.0                0              0.0              1.00           0.0   \n",
       "\n",
       "   deck_risk  oe_constraint  ppap_risk  stop_auto_buy  rev_stop  \n",
       "0          0              0          0              1         0  \n",
       "1          0              0          1              1         0  \n",
       "2          0              0          0              1         0  \n",
       "3          0              0          0              1         0  \n",
       "4          0              0          0              1         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.drop(columns = 'went_on_backorder')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   national_inv      10000 non-null  float64\n",
      " 1   lead_time         10000 non-null  float64\n",
      " 2   in_transit_qty    10000 non-null  float64\n",
      " 3   forecast_6_month  10000 non-null  float64\n",
      " 4   sales_6_month     10000 non-null  float64\n",
      " 5   min_bank          10000 non-null  float64\n",
      " 6   potential_issue   10000 non-null  int64  \n",
      " 7   pieces_past_due   10000 non-null  float64\n",
      " 8   perf_6_month_avg  10000 non-null  float64\n",
      " 9   local_bo_qty      10000 non-null  float64\n",
      " 10  deck_risk         10000 non-null  int64  \n",
      " 11  oe_constraint     10000 non-null  int64  \n",
      " 12  ppap_risk         10000 non-null  int64  \n",
      " 13  stop_auto_buy     10000 non-null  int64  \n",
      " 14  rev_stop          10000 non-null  int64  \n",
      "dtypes: float64(9), int64(6)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: went_on_backorder, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset['went_on_backorder']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "### 1st pipeline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "#-----------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "numerical_cols = ['national_inv', 'lead_time', 'in_transit_qty', 'forecast_6_month', 'sales_6_month', \n",
    "                  'min_bank', 'pieces_past_due', 'perf_6_month_avg', 'local_bo_qty']\n",
    "categorical_cols = ['potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk', 'stop_auto_buy', 'rev_stop']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "num_scale_train = scaler.fit_transform(X_train[numerical_cols])\n",
    "num_scale_test = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "X_train= np.hstack((num_scale_train, X_train[categorical_cols].values))\n",
    "X_test = np.hstack((num_scale_test, X_test[categorical_cols].values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05611873,  8.26558552, -0.05416027, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.08516439,  0.92015313, -0.05416027, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.09167463, -1.28347658, -0.05416027, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.08266045,  0.18560989, -0.05416027, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.09117384,  0.3692457 , -0.05416027, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.09117384, -0.91620496, -0.05416027, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Outliers = 400\n",
      "No. of Outliers in test = 98\n"
     ]
    }
   ],
   "source": [
    "# Anomaly detection code  \n",
    "# ----------------------------------\n",
    "iso = IsolationForest(contamination=0.05).fit(X_train)\n",
    "out = iso.predict(X_train) == -1\n",
    "\n",
    "print(f\"No. of Outliers = {np.sum(out)}\")\n",
    "X_train1 = X_train[~out]\n",
    "y_train1 = y_train[~out]\n",
    "\n",
    "#Just to identify the outliers\n",
    "outtest = iso.predict(X_test) == -1\n",
    "print(f\"No. of Outliers in test = {np.sum(outtest)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers from test data will not be removed so as to mimic real-world unpredictability. \n",
    "In such a situation, we can not control what data is fed into the model after its deployment, and as such, will contain noisy inputs and extreme values.  \n",
    "\n",
    "It can also provide me with an honest model evaluation, testing the model's robustness and generalization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for pipeline with feature selection and classification and hyperparameter tuning  \n",
    "# ----------------------------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "param_grid1 = {\n",
    "    'select__k': [4, 7, 10, 12, 15],\n",
    "    'rf__max_depth': [6,10,15],\n",
    "    'rf__max_features': ['sqrt', 'log2'],\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__min_samples_leaf':[2,5,7]\n",
    "}\n",
    "\n",
    "pipe1 = Pipeline([\n",
    "    ('select',SelectKBest(score_func=f_classif)),\n",
    "    ('rf',RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:115: UserWarning: Features [14] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 12.516682624816895s\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------\n",
    "\n",
    "start = time()\n",
    "\n",
    "model_grid1 = RandomizedSearchCV(pipe1,  param_grid1, n_jobs=5, cv=10,random_state=42)\n",
    "model_grid1.fit(X_train1, y_train1)\n",
    "\n",
    "stop = time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select__k': 15,\n",
       " 'rf__n_estimators': 200,\n",
       " 'rf__min_samples_leaf': 5,\n",
       " 'rf__max_features': 'sqrt',\n",
       " 'rf__max_depth': 15}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "#-----------------------\n",
    "model_grid1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Mean test (CV) score: 0.868\n",
      "Best Model Std test (CV) score:  0.0093\n"
     ]
    }
   ],
   "source": [
    "#Mean and Std scores\n",
    "#-----------------------\n",
    "results = pd.DataFrame(model_grid1.cv_results_)\n",
    "best_data  = results[results['rank_test_score']==1]\n",
    "mean_s = best_data['mean_test_score']\n",
    "std_s = best_data['std_test_score']\n",
    "\n",
    "print(\"Best Model Mean test (CV) score:\",round(float(mean_s),4))\n",
    "print(\"Best Model Std test (CV) score: \",round(float(std_s),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe I can look at max_depth being greater than 15, to see if there is an improvement in the model. I can also reduce the number of features to use for the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:115: UserWarning: Features [14] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 44.851775884628296s\n"
     ]
    }
   ],
   "source": [
    "#Second iteration:\n",
    "#-----------------------\n",
    "param_grid1 = {\n",
    "    'select__k': [4,5,8,9],\n",
    "    'rf__max_depth': [15,17,20,24],\n",
    "    'rf__max_features': ['sqrt','log2',None],\n",
    "    'rf__n_estimators': [200,250,300],\n",
    "    'rf__min_samples_leaf':[2,5,7]\n",
    "}\n",
    "\n",
    "pipe1 = Pipeline([\n",
    "    ('select',SelectKBest(score_func=f_classif)),\n",
    "    ('rf',RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "start = time()\n",
    "\n",
    "model_grid1 = RandomizedSearchCV(pipe1,  param_grid1, n_jobs=5, cv=10, random_state=42)\n",
    "model_grid1.fit(X_train1, y_train1)\n",
    "\n",
    "stop = time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select__k': 8,\n",
       " 'rf__n_estimators': 300,\n",
       " 'rf__min_samples_leaf': 2,\n",
       " 'rf__max_features': 'log2',\n",
       " 'rf__max_depth': 17}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "#-----------------------\n",
    "model_grid1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Mean test (CV) score: 0.857\n",
      "Best Model Std test (CV) score:  0.0066\n"
     ]
    }
   ],
   "source": [
    "#Mean and Std scores\n",
    "#-----------------------\n",
    "results = pd.DataFrame(model_grid1.cv_results_)\n",
    "best_data  = results[results['rank_test_score']==1]\n",
    "mean_s = best_data['mean_test_score']\n",
    "std_s = best_data['std_test_score']\n",
    "\n",
    "print(\"Best Model Mean test (CV) score:\",round(float(mean_s),4))\n",
    "print(\"Best Model Std test (CV) score: \",round(float(std_s),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first iteration did perform better than the second in terms of mean scores, but that could be because it was using all the features. \n",
    "\n",
    "Achieving a score of 0.857 while using only eight features and a max depth of 17 is still really good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3462</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>3637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  3462   297\n",
       "1   204  3637"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix \n",
    "#-----------------------\n",
    "train_pred = model_grid1.predict(X_train1)\n",
    "pd.DataFrame(confusion_matrix(y_train1, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      3759\n",
      "           1       0.92      0.95      0.94      3841\n",
      "\n",
      "    accuracy                           0.93      7600\n",
      "   macro avg       0.93      0.93      0.93      7600\n",
      "weighted avg       0.93      0.93      0.93      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report \n",
    "#-----------------------\n",
    "print(classification_report(y_train1, train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:115: UserWarning: Features [14] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 63.33665060997009s\n"
     ]
    }
   ],
   "source": [
    "#Third iteration:\n",
    "#-----------------------\n",
    "param_grid1 = {\n",
    "    'select__k': [4,5,8,9],\n",
    "    'rf__max_depth': [15,17,20,24],\n",
    "    'rf__max_features': ['sqrt','log2',None],\n",
    "    'rf__n_estimators': [300,350,400],\n",
    "    'rf__min_samples_leaf':[2,5,7]\n",
    "}\n",
    "\n",
    "pipe1 = Pipeline([\n",
    "    ('select',SelectKBest(score_func=f_classif)),\n",
    "    ('rf',RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "start = time()\n",
    "\n",
    "model_grid1 = RandomizedSearchCV(pipe1,  param_grid1, n_jobs=5, cv=10, random_state=42)\n",
    "model_grid1.fit(X_train1, y_train1)\n",
    "\n",
    "stop = time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select__k': 8,\n",
       " 'rf__n_estimators': 400,\n",
       " 'rf__min_samples_leaf': 2,\n",
       " 'rf__max_features': 'log2',\n",
       " 'rf__max_depth': 17}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "#-----------------------\n",
    "model_grid1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Mean test (CV) score: 0.8576\n",
      "Best Model Std test (CV) score:  0.0066\n"
     ]
    }
   ],
   "source": [
    "#Mean and Std scores\n",
    "#-----------------------\n",
    "results = pd.DataFrame(model_grid1.cv_results_)\n",
    "best_data  = results[results['rank_test_score']==1]\n",
    "mean_s = best_data['mean_test_score']\n",
    "std_s = best_data['std_test_score']\n",
    "\n",
    "print(\"Best Model Mean test (CV) score:\",round(float(mean_s),4))\n",
    "print(\"Best Model Std test (CV) score: \",round(float(std_s),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model score does see a slight improvement with the increase in \"n_estimators\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201</td>\n",
       "      <td>3640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  3461   298\n",
       "1   201  3640"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix \n",
    "#-----------------------\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "train_pred = model_grid1.predict(X_train1)\n",
    "pd.DataFrame(confusion_matrix(y_train1, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      3759\n",
      "           1       0.92      0.95      0.94      3841\n",
      "\n",
      "    accuracy                           0.93      7600\n",
      "   macro avg       0.93      0.93      0.93      7600\n",
      "weighted avg       0.93      0.93      0.93      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_train1, train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third iteration has very few minor improvements, as seen in the precision score for class (0), but that seems about it.\n",
    "\n",
    "There is still some improvement, so I will consider the third iteration to be the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select__k': 8,\n",
       " 'rf__n_estimators': 400,\n",
       " 'rf__min_samples_leaf': 2,\n",
       " 'rf__max_features': 'log2',\n",
       " 'rf__max_depth': 17}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Prediction on test data\n",
    "#-----------------------\n",
    "y_pred = model_grid1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>881</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  881  155\n",
       "1  118  846"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "#-----------------------\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87      1036\n",
      "           1       0.85      0.88      0.86       964\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the best hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E204)\n",
    "# ---------------------------------------------\n",
    "\n",
    "Feature selection Parameters:\n",
    "------------------------------\n",
    "k: 8\n",
    "\n",
    "Model Parameters: \n",
    "------------------------------\n",
    "n_estimators: 400\n",
    "min_samples_leaf: 2\n",
    "max_features: 'log2'\n",
    "rf__max_depth: 17\n",
    "\n",
    "Performance using test data:\n",
    "----------------------------\n",
    "Accuracy , Precision, Recall and f1-score  : 0.93 \n",
    "\n",
    "\n",
    "Performance using test data:\n",
    "-----------------------------\n",
    "Accuracy: 0.86\n",
    "Precision, Recall and f1-score  : 0.86 \n",
    "\n",
    "\n",
    "For both the training and testing sets, the F1 scores for each class were very close, indicating that the model performs consistently across both class 0 and class 1. There also does not appear to be any significant bias toward either class. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "### 2nd pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Outliers = 410\n",
      "No. of Outliers in test = 111\n"
     ]
    }
   ],
   "source": [
    "# Anomaly detection code  (Question #E205)\n",
    "# ----------------------------------\n",
    "oc_svm =  OneClassSVM(kernel='rbf', gamma='auto', nu=0.05)\n",
    "oc_svm =  oc_svm.fit(X_train)\n",
    "\n",
    "out_svm = oc_svm.predict(X_train) == -1\n",
    "\n",
    "print(f\"No. of Outliers = {np.sum(out_svm)}\")\n",
    "X_train2 = X_train[~out_svm]\n",
    "y_train2 = y_train[~out_svm]\n",
    "\n",
    "#Just to identify the outliers\n",
    "outtest_svm = oc_svm.predict(X_test) == -1\n",
    "print(f\"No. of Outliers in test = {np.sum(outtest_svm)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers from test data will not be removed so as to mimic real-world unpredictability. \n",
    "In such a situation, we can not control what data is fed into the model after its deployment, and as such, will contain noisy inputs and extreme values.  \n",
    "\n",
    "It can also provide me with an honest model evaluation, testing the model's robustness and generalization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Training time: 209.41144180297852s\n"
     ]
    }
   ],
   "source": [
    "# Code for pipeline with feature selection and classification and hyperparameter tuning\n",
    "# ----------------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#First iteration\n",
    "#-----------------------\n",
    "param_grid2 = {   \n",
    "    'rfe__n_features_to_select': [5, 7,8,9,10],\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma' : [0.01,1,'scale'],\n",
    "    'svc__kernel' : ['linear', 'rbf', 'poly'],\n",
    "}\n",
    "\n",
    "pipe2 = Pipeline([\n",
    "    ('rfe' , RFE(LogisticRegression())),\n",
    "    ('svc', SVC(probability=True, random_state=42))\n",
    "    \n",
    "])\n",
    "\n",
    "start = time()\n",
    "\n",
    "model_grid2 = RandomizedSearchCV(pipe2,  param_grid2, n_jobs=7, cv=10, random_state=42,verbose=2)\n",
    "model_grid2.fit(X_train2, y_train2)\n",
    "\n",
    "stop = time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__kernel': 'linear',\n",
       " 'svc__gamma': 0.01,\n",
       " 'svc__C': 1,\n",
       " 'rfe__n_features_to_select': 10}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "#-----------------------\n",
    "model_grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Mean test (CV) score: 0.7295\n",
      "Best Model Std test (CV) score:  0.0202\n"
     ]
    }
   ],
   "source": [
    "#Mean and Std scores\n",
    "#-----------------------\n",
    "results = pd.DataFrame(model_grid2.cv_results_)\n",
    "best_data  = results[results['rank_test_score']==1]\n",
    "mean_s = best_data['mean_test_score']\n",
    "std_s = best_data['std_test_score']\n",
    "\n",
    "print(\"Best Model Mean test (CV) score:\",round(float(mean_s),4))\n",
    "print(\"Best Model Std test (CV) score: \",round(float(std_s),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2439</td>\n",
       "      <td>1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>744</td>\n",
       "      <td>3084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2439  1323\n",
       "1   744  3084"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix \n",
    "#-----------------------\n",
    "train_pred2= model_grid2.predict(X_train2)\n",
    "pd.DataFrame(confusion_matrix(y_train2, train_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.65      0.70      3762\n",
      "           1       0.70      0.81      0.75      3828\n",
      "\n",
      "    accuracy                           0.73      7590\n",
      "   macro avg       0.73      0.73      0.73      7590\n",
      "weighted avg       0.73      0.73      0.73      7590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_train2, train_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not that great, lets try changing the parameters abit more..\n",
    "\n",
    "I tried a different \"estimator\" parameter for the RFE model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Training time: 523.6520590782166s\n"
     ]
    }
   ],
   "source": [
    "#Second Iteration\n",
    "#-----------------------\n",
    "param_grid2 = {   \n",
    "    'rfe__n_features_to_select': [4,5,6,7,8],\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma' : [0.001 ,0.01,1],\n",
    "    'svc__kernel' : ['linear', 'rbf', 'poly'],\n",
    "}\n",
    "\n",
    "pipe2 = Pipeline([\n",
    "    ('rfe' , RFE(estimator= SVC(kernel=\"linear\"))),\n",
    "    ('svc', SVC(probability=True, random_state=42))\n",
    "    \n",
    "])\n",
    "\n",
    "start = time()\n",
    "\n",
    "model_grid2 = RandomizedSearchCV(pipe2,  param_grid2, n_jobs=7, cv=10, random_state=42,verbose=2)\n",
    "model_grid2.fit(X_train2, y_train2)\n",
    "\n",
    "stop = time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__kernel': 'linear',\n",
       " 'svc__gamma': 1,\n",
       " 'svc__C': 10,\n",
       " 'rfe__n_features_to_select': 4}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "#-----------------------\n",
    "model_grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Mean test (CV) score: 0.6736\n",
      "Best Model Std test (CV) score:  0.0127\n"
     ]
    }
   ],
   "source": [
    "#Mean and Std scores\n",
    "#-----------------------\n",
    "results = pd.DataFrame(model_grid2.cv_results_)\n",
    "best_data  = results[results['rank_test_score']==1]\n",
    "mean_s = best_data['mean_test_score']\n",
    "std_s = best_data['std_test_score']\n",
    "\n",
    "print(\"Best Model Mean test (CV) score:\",round(float(mean_s),4))\n",
    "print(\"Best Model Std test (CV) score: \",round(float(std_s),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1401</td>\n",
       "      <td>2361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>3721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  1401  2361\n",
       "1   107  3721"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix \n",
    "#-----------------------\n",
    "train_pred2= model_grid2.predict(X_train2)\n",
    "pd.DataFrame(confusion_matrix(y_train2, train_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.37      0.53      3762\n",
      "           1       0.61      0.97      0.75      3828\n",
      "\n",
      "    accuracy                           0.67      7590\n",
      "   macro avg       0.77      0.67      0.64      7590\n",
      "weighted avg       0.77      0.67      0.64      7590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_train2, train_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is much worse than that of the first iteration. \n",
    "\n",
    "I will add a new parameter called \"step\" and change the estimator again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Training time: 254.47905850410461s\n"
     ]
    }
   ],
   "source": [
    "#Third Iteration\n",
    "#-----------------------\n",
    "param_grid2 = {\n",
    "    'rfe__step' : [0.1,0.2,0.5],\n",
    "    \n",
    "    'rfe__n_features_to_select': [3,5, 7,8],\n",
    "    'svc__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'svc__gamma' : [0.001, 0.01, 0.1, 1,'scale'],\n",
    "    'svc__kernel' : ['linear', 'rbf'],\n",
    "}\n",
    "\n",
    "pipe2 = Pipeline([\n",
    "    ('rfe' , RFE(DecisionTreeClassifier())),\n",
    "    ('svc', SVC(probability=True, random_state=42))\n",
    "    \n",
    "])\n",
    "\n",
    "start = time()\n",
    "\n",
    "model_grid2 = RandomizedSearchCV(pipe2,  param_grid2, n_jobs=7, cv=10, random_state=42,verbose=2)\n",
    "model_grid2.fit(X_train2, y_train2)\n",
    "\n",
    "stop = time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__kernel': 'linear',\n",
       " 'svc__gamma': 0.001,\n",
       " 'svc__C': 100,\n",
       " 'rfe__step': 0.2,\n",
       " 'rfe__n_features_to_select': 5}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "#-----------------------\n",
    "model_grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Mean test (CV) score: 0.7404\n",
      "Best Model Std test (CV) score:  0.0136\n"
     ]
    }
   ],
   "source": [
    "#Mean and Std scores\n",
    "#-----------------------\n",
    "results = pd.DataFrame(model_grid2.cv_results_)\n",
    "best_data  = results[results['rank_test_score']==1]\n",
    "mean_s = best_data['mean_test_score']\n",
    "std_s = best_data['std_test_score']\n",
    "\n",
    "print(\"Best Model Mean test (CV) score:\", round(float(mean_s.values[0]), 4))\n",
    "print(\"Best Model Std test (CV) score: \", round(float(std_s.values[0]), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007</td>\n",
       "      <td>1755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210</td>\n",
       "      <td>3618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2007  1755\n",
       "1   210  3618"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix \n",
    "#-----------------------\n",
    "train_pred2= model_grid2.predict(X_train2)\n",
    "pd.DataFrame(confusion_matrix(y_train2, train_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.53      0.67      3762\n",
      "           1       0.67      0.95      0.79      3828\n",
      "\n",
      "    accuracy                           0.74      7590\n",
      "   macro avg       0.79      0.74      0.73      7590\n",
      "weighted avg       0.79      0.74      0.73      7590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_train2, train_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, there seems to be a good improvement when using the 'step' parameter. \n",
    "For the fourth iteration, I can add a few more parameters to see if there is any further improvement. \n",
    "\n",
    "I can increase the value of the C parameter. While this can make the model fit the data more closely, it does increase the risk of overfitting and can greatly increase the computation time. As such, it's best to keep it as is. \n",
    "\n",
    "I want to see if using \"SVC(kernel='linear')\" as the estimator would be better with \"step\". This method keeps both parts of the pipeline within the SVM family. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Training time: 306.4144217967987s\n"
     ]
    }
   ],
   "source": [
    "#Fourth iteration:\n",
    "#-----------------------\n",
    "param_grid2 = {\n",
    "    'rfe__step' : [0.15,0.2,0.5],\n",
    "    'rfe__n_features_to_select': [3,5, 7,8],\n",
    "    'svc__C': [1,10, 100],\n",
    "    'svc__gamma' : [0.001, 0.01, 0.1, 1,'scale'],\n",
    "    'svc__tol': [1e-3, 1e-2,1e-1],\n",
    "    'svc__kernel' : ['linear', 'rbf'],\n",
    "}\n",
    "\n",
    "pipe2 = Pipeline([\n",
    "    ('rfe' , RFE(SVC(kernel='linear'))),\n",
    "    ('svc', SVC(probability=True, random_state=42))\n",
    "    \n",
    "])\n",
    "\n",
    "start = time()\n",
    "\n",
    "model_grid2 = RandomizedSearchCV(pipe2,  param_grid2, n_jobs=7, cv=10, random_state=42,verbose=2)\n",
    "model_grid2.fit(X_train2, y_train2)\n",
    "\n",
    "stop = time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__tol': 0.001,\n",
       " 'svc__kernel': 'rbf',\n",
       " 'svc__gamma': 'scale',\n",
       " 'svc__C': 100,\n",
       " 'rfe__step': 0.15,\n",
       " 'rfe__n_features_to_select': 3}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "#-----------------------\n",
    "model_grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Mean test (CV) score: 0.8105\n",
      "Best Model Std test (CV) score:  0.0092\n"
     ]
    }
   ],
   "source": [
    "#Mean and Std scores\n",
    "#-----------------------\n",
    "results = pd.DataFrame(model_grid2.cv_results_)\n",
    "best_data  = results[results['rank_test_score']==1]\n",
    "mean_s = best_data['mean_test_score']\n",
    "std_s = best_data['std_test_score']\n",
    "\n",
    "print(\"Best Model Mean test (CV) score:\", round(float(mean_s.values[0]), 4))\n",
    "print(\"Best Model Std test (CV) score: \", round(float(std_s.values[0]), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2854</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>487</td>\n",
       "      <td>3341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2854   908\n",
       "1   487  3341"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix \n",
    "#-----------------------\n",
    "train_pred2= model_grid2.predict(X_train2)\n",
    "pd.DataFrame(confusion_matrix(y_train2, train_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80      3762\n",
      "           1       0.79      0.87      0.83      3828\n",
      "\n",
      "    accuracy                           0.82      7590\n",
      "   macro avg       0.82      0.82      0.82      7590\n",
      "weighted avg       0.82      0.82      0.82      7590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_train2, train_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, there is a substantial improvement with these parameters. So, for this pipeline, I will consider these parameters the best. The only potential concern is underfitting, as the model uses only 3 out of 15 features, which might limit its ability to capture the complexity of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__tol': 0.001,\n",
       " 'svc__kernel': 'rbf',\n",
       " 'svc__gamma': 'scale',\n",
       " 'svc__C': 100,\n",
       " 'rfe__step': 0.15,\n",
       " 'rfe__n_features_to_select': 3}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>778</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  778  258\n",
       "1  123  841"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Prediction on test data\n",
    "#-----------------------\n",
    "y_pred2 = model_grid2.predict(X_test)\n",
    "#confusion matrix \n",
    "#----------------------\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80      1036\n",
      "           1       0.77      0.87      0.82       964\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.81      0.81      0.81      2000\n",
      "weighted avg       0.82      0.81      0.81      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the best hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E208)\n",
    "# ---------------------------------------------\n",
    "\n",
    "\n",
    "Model Parameters:\n",
    "----------------------\n",
    "tol: 0.001\n",
    "kernel: 'rbf'\n",
    "gamma: scale\n",
    "C: 100\n",
    "\n",
    "Feature selection Parameters:\n",
    "-------------------------------\n",
    "step: 0.15\n",
    "n_features_to_select: 3\n",
    "\n",
    "\n",
    "\n",
    "Performance using training data:\n",
    "----------------------------\n",
    "Accuracy: 0.82\n",
    "Precision: 0.82 \n",
    "Recall and f1-score  : 0.81 \n",
    "\n",
    "\n",
    "Performance using test data:\n",
    "-----------------------------\n",
    "Accuracy, Precision, Recall and f1-score  : 0.81 \n",
    "\n",
    "\n",
    "This model performs and generalizes well, as the scores are quite similar on both the training and testing sets. However, since the scores are not particularly high and only 3 out of 15 features were used, there is a possibility of underfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3rd pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly detection code  \n",
    "# ----------------------------------\n",
    "envelope = EllipticEnvelope(support_fraction=1, contamination=0.05)\n",
    "envelope = envelope.fit(X_train)\n",
    "\n",
    "out_envelope = envelope.predict(X_train) == -1\n",
    "\n",
    "print(f\"No. of Outliers = {np.sum(out_envelope)}\")\n",
    "X_train3 = X_train[~out_envelope]\n",
    "y_train3 = y_train[~out_envelope]\n",
    "\n",
    "#Just to identify the outliers\n",
    "outtest_envelope = envelope.predict(X_test) == -1\n",
    "print(f\"No. of Outliers in test = {np.sum(outtest_envelope)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers from test data will not be removed so as to mimic real-world unpredictability. \n",
    "In such a situation, we can not control what data is fed into the model after its deployment, and as such, will contain noisy inputs and extreme values.  \n",
    "\n",
    "It can also provide me with an honest model evaluation, testing the model's robustness and generalization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Training time: 25.83633804321289s\n"
     ]
    }
   ],
   "source": [
    "# Code for pipeline with feature selection and classification and hyperparameter tuning\n",
    "# ----------------------------------\n",
    "\n",
    "#First iteration\n",
    "#-----------------------\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "param_grid3 = {\n",
    "    'select__percentile': [20, 30, 40,50,60],\n",
    "    'gb__max_depth': [3, 5, 7],\n",
    "    'gb__learning_rate': [0.01,0.05, 0.2, 0.25],\n",
    "    'gb__min_samples_split': [3, 5, 10],\n",
    "    'gb__subsample': [0.4,0.5,0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "\n",
    "pipe3 = Pipeline([\n",
    "    ('select', SelectPercentile(score_func=mutual_info_classif)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "start = time()\n",
    "\n",
    "model_grid3 = RandomizedSearchCV(pipe3,  param_grid3, n_jobs=7, cv=10, random_state=42,verbose=2)\n",
    "model_grid3.fit(X_train3, y_train3)\n",
    "\n",
    "stop = time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select__percentile': 50,\n",
       " 'gb__subsample': 0.6,\n",
       " 'gb__min_samples_split': 10,\n",
       " 'gb__max_depth': 5,\n",
       " 'gb__learning_rate': 0.2}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "#-----------------------\n",
    "model_grid3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Mean test (CV) score: 0.872\n",
      "Best Model Std test (CV) score:  0.0138\n"
     ]
    }
   ],
   "source": [
    "#Mean and Std scores\n",
    "#-----------------------\n",
    "results = pd.DataFrame(model_grid3.cv_results_)\n",
    "best_data  = results[results['rank_test_score']==1]\n",
    "mean_s = best_data['mean_test_score']\n",
    "std_s = best_data['std_test_score']\n",
    "\n",
    "print(\"Best Model Mean test (CV) score:\", round(float(mean_s.values), 4))\n",
    "print(\"Best Model Std test (CV) score: \", round(float(std_s.values), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3481</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>3597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  3481   298\n",
       "1   224  3597"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix \n",
    "#-----------------------\n",
    "train_pred3= model_grid3.predict(X_train3)\n",
    "pd.DataFrame(confusion_matrix(y_train3, train_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      3779\n",
      "           1       0.92      0.94      0.93      3821\n",
      "\n",
      "    accuracy                           0.93      7600\n",
      "   macro avg       0.93      0.93      0.93      7600\n",
      "weighted avg       0.93      0.93      0.93      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_train3, train_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does perform well on the training set, but there may be some room for improvement by exploring another parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Training time: 34.85167169570923s\n"
     ]
    }
   ],
   "source": [
    "#Second iteration\n",
    "#-----------------------\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "param_grid3 = {\n",
    "    'select__percentile': [10, 30,50,70,80],\n",
    "    'gb__max_depth': [3, 5, 7],\n",
    "    'gb__learning_rate': [0.01,0.05, 0.2, 0.25],\n",
    "    'gb__n_estimators': [50, 100, 200, 300],\n",
    "    'gb__subsample': [0.4,0.5,0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "\n",
    "pipe3 = Pipeline([\n",
    "    ('select', SelectPercentile(score_func=mutual_info_classif)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "start = time()\n",
    "\n",
    "model_grid3 = RandomizedSearchCV(pipe3,  param_grid3, n_jobs=7, cv=10, random_state=42,verbose=2)\n",
    "model_grid3.fit(X_train3, y_train3)\n",
    "\n",
    "stop = time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select__percentile': 70,\n",
       " 'gb__subsample': 1.0,\n",
       " 'gb__n_estimators': 50,\n",
       " 'gb__max_depth': 7,\n",
       " 'gb__learning_rate': 0.25}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "#-----------------------\n",
    "model_grid3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Mean test (CV) score: 0.8768\n",
      "Best Model Std test (CV) score:  0.0089\n"
     ]
    }
   ],
   "source": [
    "#Mean and Std scores\n",
    "#-----------------------\n",
    "results = pd.DataFrame(model_grid3.cv_results_)\n",
    "best_data  = results[results['rank_test_score']==1]\n",
    "mean_s = best_data['mean_test_score']\n",
    "std_s = best_data['std_test_score']\n",
    "\n",
    "print(\"Best Model Mean test (CV) score:\", round(float(mean_s.values), 4))\n",
    "print(\"Best Model Std test (CV) score: \", round(float(std_s.values), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3673</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>3749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  3673   106\n",
       "1    72  3749"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix \n",
    "#-----------------------\n",
    "train_pred3= model_grid3.predict(X_train3)\n",
    "pd.DataFrame(confusion_matrix(y_train3, train_pred3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      3779\n",
      "           1       0.97      0.98      0.98      3821\n",
      "\n",
      "    accuracy                           0.98      7600\n",
      "   macro avg       0.98      0.98      0.98      7600\n",
      "weighted avg       0.98      0.98      0.98      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_train3, train_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the performance of the model has improved much more when using \"n_estimators\" over \"min_samples_split\". My only concern is that the model is overfitting.\n",
    "Maybe tweaking the range and using the \"min_samples_split\" parameter could provide reasonable results. I will also increase the no. of combinations to search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "Training time: 444.5483889579773s\n"
     ]
    }
   ],
   "source": [
    "#Third Iteration\n",
    "#-----------------------\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "param_grid3 = {\n",
    "    'select__percentile': [10,30,50],\n",
    "    'gb__max_depth': [7,12,15,17,20,25],\n",
    "    'gb__learning_rate': [0.01, 0.2, 0.25,0.3],\n",
    "    'gb__n_estimators': [50,100, 200, 300],\n",
    "    'gb__subsample': [0.6, 0.8,1],\n",
    "    'gb__min_samples_split': [5,10,15]\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "pipe3 = Pipeline([\n",
    "    ('select', SelectPercentile(score_func=mutual_info_classif)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "start = time()\n",
    "\n",
    "model_grid3 = RandomizedSearchCV(pipe3,  param_grid3, n_jobs=7, cv=10, random_state=42,verbose=2,n_iter=50)\n",
    "model_grid3.fit(X_train3, y_train3)\n",
    "\n",
    "stop = time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select__percentile': 50,\n",
       " 'gb__subsample': 0.6,\n",
       " 'gb__n_estimators': 50,\n",
       " 'gb__min_samples_split': 5,\n",
       " 'gb__max_depth': 12,\n",
       " 'gb__learning_rate': 0.25}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "#-----------------------\n",
    "model_grid3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Mean test (CV) score: 0.8758\n",
      "Best Model Std test (CV) score:  0.0115\n"
     ]
    }
   ],
   "source": [
    "#Mean and Std scores\n",
    "#-----------------------\n",
    "results = pd.DataFrame(model_grid3.cv_results_)\n",
    "best_data  = results[results['rank_test_score']==1]\n",
    "mean_s = best_data['mean_test_score']\n",
    "std_s = best_data['std_test_score']\n",
    "\n",
    "print(\"Best Model Mean test (CV) score:\", round(float(mean_s.values), 4))\n",
    "print(\"Best Model Std test (CV) score: \", round(float(std_s.values), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3728</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>3781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  3728    51\n",
       "1    40  3781"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix \n",
    "#-----------------------\n",
    "train_pred3= model_grid3.predict(X_train3)\n",
    "pd.DataFrame(confusion_matrix(y_train3, train_pred3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3779\n",
      "           1       0.99      0.99      0.99      3821\n",
      "\n",
      "    accuracy                           0.99      7600\n",
      "   macro avg       0.99      0.99      0.99      7600\n",
      "weighted avg       0.99      0.99      0.99      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_train3, train_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters give results that appear as overfitting as well. I have tried other combinations and parameter ranges, each of which gives near-perfect predictions over training data, which is likely overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Training time: 94.01213574409485s\n"
     ]
    }
   ],
   "source": [
    "#Fourth Iteration\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "param_grid3 = {\n",
    "    'select__percentile': [20, 30, 40,50,60],\n",
    "    'gb__max_depth': [7,12,15,17,20,25],\n",
    "    'gb__learning_rate': [0.01,0.05, 0.2, 0.25],\n",
    "    'gb__min_samples_split': [ 5, 10,15],\n",
    "    'gb__subsample': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "\n",
    "pipe3 = Pipeline([\n",
    "    ('select', SelectPercentile(score_func=mutual_info_classif)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "start = time()\n",
    "\n",
    "model_grid3 = RandomizedSearchCV(pipe3,  param_grid3, n_jobs=7, cv=10, random_state=42,verbose=2)\n",
    "model_grid3.fit(X_train3, y_train3)\n",
    "\n",
    "stop = time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select__percentile': 60,\n",
       " 'gb__subsample': 0.8,\n",
       " 'gb__min_samples_split': 5,\n",
       " 'gb__max_depth': 25,\n",
       " 'gb__learning_rate': 0.25}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "#-----------------------\n",
    "model_grid3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Mean test (CV) score: 0.8797\n",
      "Best Model Std test (CV) score:  0.0099\n"
     ]
    }
   ],
   "source": [
    "#Mean and Std scores\n",
    "#-----------------------\n",
    "results = pd.DataFrame(model_grid3.cv_results_)\n",
    "best_data  = results[results['rank_test_score']==1]\n",
    "mean_s = best_data['mean_test_score']\n",
    "std_s = best_data['std_test_score']\n",
    "\n",
    "print(\"Best Model Mean test (CV) score:\", round(float(mean_s.values), 4))\n",
    "print(\"Best Model Std test (CV) score: \", round(float(std_s.values), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3765</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>3801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  3765    14\n",
       "1    20  3801"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix \n",
    "#-----------------------\n",
    "train_pred3= model_grid3.predict(X_train3)\n",
    "pd.DataFrame(confusion_matrix(y_train3, train_pred3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3779\n",
      "           1       1.00      0.99      1.00      3821\n",
      "\n",
      "    accuracy                           1.00      7600\n",
      "   macro avg       1.00      1.00      1.00      7600\n",
      "weighted avg       1.00      1.00      1.00      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_train3, train_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first iteration provided a more reasonable result and,  as such, will be considered the best for this pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select__percentile': 50,\n",
       " 'gb__subsample': 0.6,\n",
       " 'gb__min_samples_split': 10,\n",
       " 'gb__max_depth': 5,\n",
       " 'gb__learning_rate': 0.2}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>890</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  890  146\n",
       "1  108  856"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Prediction on test data\n",
    "#-----------------------\n",
    "y_pred3 = model_grid3.predict(X_test)\n",
    "#confusion matrix \n",
    "#----------------------\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88      1036\n",
      "           1       0.85      0.89      0.87       964\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.87      0.87      0.87      2000\n",
      "weighted avg       0.87      0.87      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the best hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E208)\n",
    "# ---------------------------------------------\n",
    "\n",
    "Feature selection Parameters:\n",
    "------------------------------\n",
    "percentile: 50\n",
    "\n",
    "Model Parameters: \n",
    "------------------------------\n",
    "subsample: 0.6,\n",
    "min_samples_split: 10,\n",
    "max_depth: 5,\n",
    "learning_rate: 0.2\n",
    "\n",
    "\n",
    "\n",
    "Performance using training data:\n",
    "----------------------------\n",
    "Accuracy, Precision, Recall and f1-score  : 0.93 \n",
    "\n",
    "\n",
    "Performance using test data:\n",
    "-----------------------------\n",
    "Accuracy, Precision, Recall and f1-score  : 0.87 \n",
    "\n",
    "The results are very similar to that of the first pipeline. There doesnt seem to be any sort of bias toward either class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparing the pipelines and documenting the findings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 1:\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select__k': 8,\n",
       " 'rf__n_estimators': 400,\n",
       " 'rf__min_samples_leaf': 2,\n",
       " 'rf__max_features': 'log2',\n",
       " 'rf__max_depth': 17}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters:\n",
    "model_grid1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>881</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  881  155\n",
       "1  118  846"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Prediction on test data\n",
    "#-----------------------\n",
    "y_pred = model_grid1.predict(X_test)\n",
    "#confusion matrix\n",
    "#-----------------------\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87      1036\n",
      "           1       0.85      0.88      0.86       964\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PipeLine 2:\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__tol': 0.001,\n",
       " 'svc__kernel': 'rbf',\n",
       " 'svc__gamma': 'scale',\n",
       " 'svc__C': 100,\n",
       " 'rfe__step': 0.15,\n",
       " 'rfe__n_features_to_select': 3}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters:\n",
    "model_grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>778</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  778  258\n",
       "1  123  841"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Prediction on test data\n",
    "#-----------------------\n",
    "y_pred2 = model_grid2.predict(X_test)\n",
    "#confusion matrix \n",
    "#----------------------\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80      1036\n",
      "           1       0.77      0.87      0.82       964\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.81      0.81      0.81      2000\n",
      "weighted avg       0.82      0.81      0.81      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PipeLine 3:\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select__percentile': 50,\n",
       " 'gb__subsample': 0.6,\n",
       " 'gb__min_samples_split': 10,\n",
       " 'gb__max_depth': 5,\n",
       " 'gb__learning_rate': 0.2}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters\n",
    "#-----------------------\n",
    "model_grid3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>890</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  890  146\n",
       "1  108  856"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Prediction on test data\n",
    "#-----------------------\n",
    "y_pred3 = model_grid3.predict(X_test)\n",
    "#confusion matrix \n",
    "#----------------------\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88      1036\n",
      "           1       0.85      0.89      0.87       964\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.87      0.87      0.87      2000\n",
      "weighted avg       0.87      0.87      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#-----------------------\n",
    "print(classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your analysis in this cell (Question #E213)\n",
    "# ----------------------------------\n",
    "\n",
    "Pipeline 1:\n",
    "Performance using test data:\n",
    "-----------------------------\n",
    "Accuracy , Precision, Recall and f1-score: 0.86 \n",
    "\n",
    "\n",
    "Pipeline 2:\n",
    "Performance using test data:\n",
    "-----------------------------\n",
    "Accuracy, Precision, Recall and f1-score: 0.81 \n",
    "\n",
    "Pipeline 3: \n",
    "Performance using test data:\n",
    "-----------------------------\n",
    "Accuracy, Precision, Recall and f1-score: 0.87 \n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "As mentioned earlier, outliers in the test data were intentionally kept to mimic real-world unpredictability. This approach provides a more honest evaluation of each model's (and its parameters) robustness and generalization capabilities. \n",
    "\n",
    "As a result, test performance across all pipelines was slightly lower than training performance.\n",
    "\n",
    "All pipelines show no significant bias towards either class, as seen from the similar f1-scores. \n",
    "\n",
    "Among the three, Pipeline 3 displayed the best performance, with Precision, Recall, and F1-score all at 0.87. Even when comparing their misclassification, pipeline 3 has the lowest, with only 254.\n",
    "\n",
    "It achieved the lowest number of false negatives (108), reducing the risk of missing actual backorders. It also achieved the lowest number of false positives (146), avoiding unnecessary allocation of resources to products, thereby improving operational efficiency.\n",
    "\n",
    "All of this makes Pipeline 3 the most efficient and reliable option for predicting product backorders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pickling the required pipeline/models to be used in Part 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('select',\n",
       "                 SelectPercentile(percentile=50,\n",
       "                                  score_func=<function mutual_info_classif at 0x7fc98b88b9d8>)),\n",
       "                ('gb',\n",
       "                 GradientBoostingClassifier(learning_rate=0.2, max_depth=5,\n",
       "                                            min_samples_split=10,\n",
       "                                            random_state=42, subsample=0.6))])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Pipeline - Model and Parameters\n",
    "pickle.dump(model_grid3.best_estimator_, open(\"best_pipeline.pkl\", \"wb\"))\n",
    "\n",
    "#Anomaly Detection model\n",
    "pickle.dump(envelope, open(\"envelope_AD_model.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
